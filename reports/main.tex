\documentclass{article}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}

\title{Project Proposal: Novel Methods for Determining Neuron Sensitivity in Large Language Models}
\author{
  [Welby Seely] \\
  \texttt{[wseely@emich.edu]}
}
\date{\today}

\begin{document}

\maketitle

\section*{Introduction}
With the advent of the transformer model and its popularization through services like ChatGPT, Large Language Models (LLMs) are becoming ubiquitous.
LLM integration with search engines like Bing~\cite{APNews2024Microsoft}, integrated development environments such as IntelliJ~\cite{anderson_jetbrains_2023}, and standard smartphone texting apps like Google Messages~\cite{msn_gemini_2024} are just a few examples.

As LLMs are increasingly put into production at scale, energy consumption and costs are skyrocketing, with some data centers now planning to build dedicated nuclear reactors to handle this alarmingly voracious power demand~\cite{CNBC2024Oracle}.

Scaling power generation to meet demand for these LLMs is treating the symptom, not the fundamental cause of these energy issues: the efficient use of computational capacity and the minimization of power consumption by the LLM itself.

A major class of optimization is predicated on Neuron Sensitivity, the responsiveness of a neuron to changes in its inputs and parameters.
The idea is that not all neurons (or parameters) contribute equally to a model's predictions.
Pruning, knowledge distillation, and sparse training techniques are all examples of optimizations and approximations that rely on this idea.
Targeting less critical parameters for approximation or elimination shows great promise in terms of improving energy efficiency.
For example, nVidia's Llama-3.1-Minitron model, through the use of pruning and distillation, is able to double or even triple inference throughput~\cite{sreenivas2024llm}.
This optimization is only made possible by first computing the importance of elements of the model, ultimately determining sensitivity of neurons in aggregate.

The more that neuron sensitivity methodologies are improved, the greater are the gains in efficiency that can be realized.
The goal of this research is to:
\begin{enumerate}
    \item understand current methodologies for determining neuron sensitivity in LLMs
    \item explore improvements that can be made to more accurately and more efficiently determine neuron sensitivity in LLMs
\end{enumerate}

The intent is that this research will be a first step towards innovating and improving optimizations for LLMs, reducing power consumption and enabling the models to run on lower powered hardware.

\section*{Related Works}
\subsection*{Current Techniques}
These are some Deep Neural Network (DNN) techniques that are in use for identifying the importance of either individual neurons or larger components in a DNN. While some of the identified articles are oriented around Convolutional Neural Networks, the techniques should still apply to LLMs (to varying degrees of efficacy.)

\begin{itemize}
    \item Coupled Structure Analysis
    \subitem Identifies dependency-based structures, in the context of pruning~\cite{ma2023llm}
    \item Activation Maximization
    \subitem Optimize an input to maximize the activation of a specific neuron or neuron layer
    \item Saliency Maps
    \subitem Visualize Neuron sensitivity by highlighting inputs that most affect a particular neuron or output~\cite{hsu2023explainable}
    \item Layer-wise Relevance Propagation
    \subitem Similar to Saliency Maps, decomposes the prediction of a network back to the individual input features~\cite{jia2022interpreting}
    \item Self-Attention Analysis (LLMs)
    \subitem Sensitivity is represented by attention weights associated with an attention head, which dictates the degree of influence of each token in a sequence model~\cite{shi2021sparsebert}
    \item Integrated Gradients
    \subitem Quantifies feature importance by integrating gradients along the path from a baseline input to the actual input~\cite{sundararajan2017axiomatic}
    \item SHAP Values (SHapley Additive exPlanation)
    \subitem Quantifies sensitivity by assigning a contribution score to each input feature based on its impact on the modelâ€™s output~\cite{nohara2022explanation}
    \item Mechanistic Interpretability
    \subitem Maps out neural circuits in order to determine which parts of a model are responsible for specific capabilities (e.g.\ arithmetic, semantic relationships between words)~\cite{singh2024rethinking}
\end{itemize}

Each of these articles will be analyzed in greater depth as a part of the research process.

\subsection*{Current Challenges}

The sheer size of LLMs challenges each of the techniques listed prior.
For example, computing gradient information on modern LLMs is prohibitively memory and compute-intensive~\cite{muralidharan2024compact}, and analyzing individual neurons becomes logistically challenging to an extreme, making techniques like Activation Maximization less viable.

Additionally, the fast pace at which research on and advancements to LLMs makes it difficult to get a holistic view on where the field is at, which is detailed more below.

\subsection*{Limitations in Current Research}
The research listed so far has been mostly oriented around coupling sensitivity/importance analysis to the specific methods of optimization, or even specific domains of problems (e.g. geospatial or medical).
This narrow scope makes it more difficult to study neuron sensitivity in LLMs in a more holistic manner.
Some optimization solutions may be more difficult to find because of the disparate nature of this knowledge.
More modern consolidated articles and knowledgebases similar to the 2018 Methods for Interpreting and Understanding Deep Neural Networks~\cite{montavon2018methods} would be of great help in this endeavor.

\section*{Initial Methodology Plan}
As mentioned prior, the goals of this research are twofold regarding neuron sensitivity and network analysis: first, understand current methodologies, second, explore improvements.
To accomplish this, an understanding of sensitivity analysis in simple neural networks must be achieved.
From there, the current sensitivity analysis techniques for DNNs and LLMs listed prior must be explored in depth, and aggregated into a single source.
Finally, a novel method of systematic sensitivity analysis will be explored, a synthesis and progression of the research.
Publicly available LLMs, such as Llama3, will be used as test data for sensitivity analysis.
\newline
\newline
Tools used may include:

\begin{itemize}
    \item PyCharm~\cite{pycharm_2024}
    \subitem Personally Favored IDE for Python Development
    \item PyTorch~\cite{pytorch_2024}
    \subitem For neural network construction and analysis
    \item TensorFlow~\cite{tensorflow_2024}
    \subitem For neural network construction and analysis
    \item TensorBoard~\cite{tensorboard_2024}
    \subitem For neural network visualization
    \item Netron~\cite{netron_2024}
    \subitem For neural network visualization
    \item ChatGPT~\cite{chatgpt_2024}
    \subitem For help with misc tasks
    \item Llama3~\cite{meta_llama_3_8B_2024}
    \subitem For help with misc tasks
    \item llama.cpp~\cite{gerganov_llama_cpp}
    \subitem For use of its analysis tools vis a vis quantization
\end{itemize}

\section*{Preliminary Data}
Large Language Models:

\begin{itemize}
    \item Llama3~\cite{meta_llama_3_8B_2024}
    \item Bert~\cite{bert_base_cased_2024}
    \item nVidia's Llama3 Minitron~\cite{llama_3_1_minitron_2024}
\end{itemize}

The Pen Machine Learning Benchmark datasets may be useful when testing neural networks\cite{Olson2017PMLB}.

\section*{Research Project Timeline}
\begin{enumerate}
    \item Background Research
    \subitem Gain foundational knowledge in sensitivity analysis within neural networks
    \subitem Completion date: Oct 4
    \item Research Current Methodologies
    \subitem Dive deeper into sensitivity analysis techniques for DNN and LLMs
    \subitem Completion date: Oct 18
    \item Aggregate Sensitivity Analysis Techniques
    \subitem Completion date: Oct 25
    \item Exploration of Novel Methodologies
    \subitem Brainstorm and propose potential improvements or new approaches to sensitivity analysis
    \subitem Completion date: Nov 8
    \item Testing with LLMs
    \subitem Apply novel methodologies to publicly available LLMs
    \subitem Completion date: Nov 22
    \item Refinement and Analysis
    \subitem Refine methodology based on testing, document, and prepare presentation
    \item Completion date: Dec 4
\end{enumerate}

\bibliographystyle{plainurl}
\bibliography{bibliography}
\thanks Thanks to ChatGPT for helping provide some ideas on subjects to look into, helping brainstorm a timeline, and generating occasionally correct bibtex citations for websites.
\end{document}