\documentclass{article}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}

\title{Project Proposal: Novel Methods for Determining Neuron Sensitivity in Large Language Models}
\author{
  [Welby Seely] \\
  \texttt{[wseely@emich.edu]}
}
\date{\today}

\begin{document}

\maketitle

\section*{Introduction}
With the advent of the transformer model and its popularization through services like ChatGPT, Large Language Models (LLMs) are becoming ubiquitous.
LLM integration with search engines like Bing~\cite{APNews2024Microsoft}, integrated development environments such as IntelliJ~\cite{anderson_jetbrains_2023}, and standard smartphone texting apps like Google Messages~\cite{msn_gemini_2024} are just a few examples.

As LLMs are increasingly put into production at scale, energy consumption and costs are skyrocketing, with some data centers now planning to build dedicated nuclear reactors to handle this alarmingly voracious power demand~\cite{CNBC2024Oracle}.

Scaling power generation to meet demand for these LLMs is treating the symptom, not the fundamental cause of these energy issues: the efficient use of computational capacity and the minimization of power consumption by the LLM itself.

A major class of optimization is predicated on Neuron Sensitivity, the responsiveness of a neuron to changes in its inputs and parameters.
The idea is that not all neurons (or parameters) contribute equally to a model's predictions.
Pruning, knowledge distillation, and sparse training techniques are all examples of optimizations and approximations that rely on this idea.
Targeting less critical parameters for approximation or elimination shows great promise in terms of improving energy efficiency.
For example, nVidia's Llama-3.1-Minitron model, through the use of pruning and distillation, is able to double or even triple inference throughput~\cite{sreenivas2024llm}.
This optimization is only made possible by first computing the importance of elements of the model, ultimately determining sensitivity of neurons in aggregate.

The more that neuron sensitivity methodologies are improved, the greater are the gains in efficiency that can be realized.
The goal of this research is to:
\begin{enumerate}
    \item understand current methodologies for determining neuron sensitivity in LLMs
    \item explore improvements that can be made to more accurately and more efficiently determine neuron sensitivity in LLMs
\end{enumerate}

The intent is that this research will be a first step towards innovating and improving optimizations for LLMs, reducing power consumption and enabling the models to run on lower powered hardware.

\section*{Related Works}
\subsection*{Current Techniques}
These are some Deep Neural Network (DNN) techniques that are in use for identifying the importance of either individual neurons or larger components in a DNN. While some of the identified articles are oriented around Convolutional Neural Networks, the techniques should still apply to LLMs (to varying degrees of efficacy.)

\begin{itemize}
    \item Coupled Structure Analysis
    \subitem Identifies dependency-based structures, in the context of pruning~\cite{ma2023llm}
    \item Activation Maximization
    \subitem Optimize an input to maximize the activation of a specific neuron or neuron layer
    \item Saliency Maps
    \subitem Visualize Neuron sensitivity by highlighting inputs that most affect a particular neuron or output~\cite{hsu2023explainable}
    \item Layer-wise Relevance Propagation
    \subitem Similar to Saliency Maps, decomposes the prediction of a network back to the individual input features~\cite{jia2022interpreting}
    \item Self-Attention Analysis (LLMs)
    \subitem Sensitivity is represented by attention weights associated with an attention head, which dictates the degree of influence of each token in a sequence model~\cite{shi2021sparsebert}
    \item Integrated Gradients
    \subitem Quantifies feature importance by integrating gradients along the path from a baseline input to the actual input~\cite{sundararajan2017axiomatic}
    \item SHAP Values (SHapley Additive exPlanation)
    \subitem Quantifies sensitivity by assigning a contribution score to each input feature based on its impact on the modelâ€™s output~\cite{nohara2022explanation}
    \item Mechanistic Interpretability
    \subitem Maps out neural circuits in order to determine which parts of a model are responsible for specific capabilities (e.g.\ arithmetic, semantic relationships between words)~\cite{singh2024rethinking}
\end{itemize}

Each of these articles will be analyzed in greater depth as a part of the research process.

\subsection*{Current Challenges}

The sheer size of LLMs challenges each of the techniques listed prior.
For example, computing gradient information on modern LLMs is prohibitively memory and compute-intensive~\cite{muralidharan2024compact}, and analyzing individual neurons becomes logistically challenging to an extreme, making techniques like Activation Maximization less viable.

Additionally, the fast pace at which research on and advancements to LLMs makes it difficult to get a holistic view on where the field is at, which is detailed more below.

\subsection*{Limitations in Current Research}
The research listed so far has been mostly oriented around coupling sensitivity/importance analysis to the specific methods of optimization, or even specific domains of problems (e.g. geospatial or medical).
This narrow scope makes it more difficult to study neuron sensitivity in LLMs in a more holistic manner.
Some optimization solutions may be more difficult to find because of the disparate nature of this knowledge.
More modern consolidated articles and knowledgebases similar to the 2018 "Methods for Interpreting and Understanding Deep Neural Networks"~\cite{montavon2018methods} would be of great help in this endeavor.

\section*{Initial Methodology Plan}
\begin{itemize}
    \item Present your proposed methodology or approach to tackle the problem
    \item Mention any techniques or tools you plan to use
    \item Explain why this approach is better than existing methods
\end{itemize}


\section*{Preliminary Data}
Provide a brief overview of any initial data you have identified


\section*{Project Timeline}
\begin{itemize}
    \item List the key milestones and deadlines for your project
    \item Break down the timeline into phases (e.g., data collection, analysis, reporting)
    \item Include expected completion dates for each stage
\end{itemize}


\bibliographystyle{plainurl}
\bibliography{bibliography}

\end{document}
