@misc{kindig2024,
  author = {Beth Kindig},
  title = {AI Power Consumption Rapidly Becoming Mission Critical},
  year = {2024},
  month = jun,
  url = {https://www.forbes.com/sites/bethkindig/2024/06/20/ai-power-consumption-rapidly-becoming-mission-critical/},
  note = {Accessed: 2024-09-16},
  journal = {Forbes},
}

@article{APNews2024Microsoft,
  title = {Microsoft bakes ChatGPT-like tech into search engine Bing},
  author = {{Associated Press}},
  journal = {AP News},
  year = {2023},
  month = {February},
  day = {7},
  url = {https://apnews.com/article/technology-science-microsoft-corp-business-software-dd445694f34a6b7a0444db9988330229},
  note = {Accessed: 2024-09-13}
}

@article{anderson_jetbrains_2023,
    title = {JetBrains releases its AI Assistant and pricing – but how does it compare to GitHub Copilot?},
    author = {Anderson, Tim},
    journal = {DevClass},
    url = {https://devclass.com/2023/12/07/jetbrains-releases-its-ai-assistant-and-pricing-but-how-does-it-compare-to-github-copilot/},
    year = {2023},
    month = {Dec},
    day = {7},
    note = {Accessed: 2024-09-13}
}

@misc{msn_gemini_2024,
    title = {Here’s a glimpse of Gemini in Google Messages, updated},
    author = {{MSN News}},
    year = {2024},
    month = {Mar},
    day = {22},
    url = {https://www.msn.com/en-us/news/technology/here-s-a-glimpse-of-gemini-in-google-messages-updated/ar-BB1kn1Db},
    note = {Accessed: 2024-09-13}
}


@article{CNBC2024Oracle,
    title = {Oracle is designing a data center that would be powered by three small nuclear reactors},
    author = {{CNBC}},
    journal = {CNBC},
    year = {2024},
    month = {September},
    day = {10},
    url = {https://www.cnbc.com/2024/09/10/oracle-is-designing-a-data-center-that-would-be-powered-by-three-small-nuclear-reactors.html},
    note = {Accessed: 2024-09-13}
}

@article{sreenivas2024llm,
  title={LLM Pruning and Distillation in Practice: The Minitron Approach},
  author={Sreenivas, Sharath Turuvekere and Muralidharan, Saurav and Joshi, Raviraj and Chochowski, Marcin and Patwary, Mostofa and Shoeybi, Mohammad and Catanzaro, Bryan and Kautz, Jan and Molchanov, Pavlo},
  journal={arXiv preprint arXiv:2408.11796},
  year={2024}
}

@article{muralidharan2024compact,
  title={Compact language models via pruning and knowledge distillation},
  author={Muralidharan, Saurav and Sreenivas, Sharath Turuvekere and Joshi, Raviraj and Chochowski, Marcin and Patwary, Mostofa and Shoeybi, Mohammad and Catanzaro, Bryan and Kautz, Jan and Molchanov, Pavlo},
  journal={arXiv preprint arXiv:2407.14679},
  year={2024}
}


@article{ma2023llm,
  title={Llm-pruner: On the structural pruning of large language models},
  author={Ma, Xinyin and Fang, Gongfan and Wang, Xinchao},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={21702--21720},
  year={2023}
}

@article{montavon2018methods,
  title={Methods for interpreting and understanding deep neural networks},
  author={Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Digital signal processing},
  volume={73},
  pages={1--15},
  year={2018},
  publisher={Elsevier}
}

@article{hsu2023explainable,
  title={Explainable GeoAI: can saliency maps help interpret artificial intelligence’s learning process? An empirical study on natural feature detection},
  author={Hsu, Chia-Yu and Li, Wenwen},
  journal={International Journal of Geographical Information Science},
  volume={37},
  number={5},
  pages={963--987},
  year={2023},
  publisher={Taylor \& Francis}
}
@inproceedings{jia2022interpreting,
  title={Interpreting Convolutional Neural Networks via Layer-Wise Relevance Propagation},
  author={Jia, Wohuan and Zhang, Shaoshuai and Jiang, Yue and Xu, Li},
  booktitle={International Conference on Adaptive and Intelligent Systems},
  pages={457--467},
  year={2022},
  organization={Springer}
}

@inproceedings{shi2021sparsebert,
  title={Sparsebert: Rethinking the importance analysis in self-attention},
  author={Shi, Han and Gao, Jiahui and Ren, Xiaozhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Kwok, James Tin-Yau},
  booktitle={International Conference on Machine Learning},
  pages={9547--9557},
  year={2021},
  organization={PMLR}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{nohara2022explanation,
  title={Explanation of machine learning models using shapley additive explanation and application for real data in hospital},
  author={Nohara, Yasunobu and Matsumoto, Koutarou and Soejima, Hidehisa and Nakashima, Naoki},
  journal={Computer Methods and Programs in Biomedicine},
  volume={214},
  pages={106584},
  year={2022},
  publisher={Elsevier}
}

@article{singh2024rethinking,
  title={Rethinking interpretability in the era of large language models},
  author={Singh, Chandan and Inala, Jeevana Priya and Galley, Michel and Caruana, Rich and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.01761},
  year={2024}
}

@misc{meta_llama_3_8B_2024,
  title        = {Meta LLaMA 3 8B},
  author       = {Meta AI},
  year         = 2024,
  url          = {https://huggingface.co/meta-llama/Meta-Llama-3-8B},
  note         = {Accessed: 2024-09-13}
}

@misc{bert_base_cased_2024,
  title        = {BERT Base Cased},
  author       = {Google},
  year         = 2024,
  url          = {https://huggingface.co/google-bert/bert-base-cased},
  note         = {Accessed: 2024-09-13}
}

@misc{llama_3_1_minitron_2024,
  title        = {LLaMA 3.1 Minitron 4B Width Base},
  author       = {NVIDIA},
  year         = 2024,
  url          = {https://huggingface.co/nvidia/Llama-3.1-Minitron-4B-Width-Base},
  note         = {Accessed: 2024-09-13}
}

@article{Olson2017PMLB,
    author="Olson, Randal S. and La Cava, William and Orzechowski, Patryk and Urbanowicz, Ryan J. and Moore, Jason H.",
    title="PMLB: a large benchmark suite for machine learning evaluation and comparison",
    journal="BioData Mining",
    year="2017",
    month="Dec",
    day="11",
    volume="10",
    number="1",
    pages="36",
    issn="1756-0381",
    doi="10.1186/s13040-017-0154-4",
    url="https://doi.org/10.1186/s13040-017-0154-4"
}

@misc{pycharm_2024,
  title        = {PyCharm},
  author       = {JetBrains},
  year         = 2024,
  url          = {https://www.jetbrains.com/pycharm/},
  note         = {Accessed: 2024-09-13}
}

@misc{pytorch_2024,
  title        = {PyTorch},
  author       = {PyTorch Team},
  year         = 2024,
  url          = {https://pytorch.org/},
  note         = {Accessed: 2024-09-13}
}

@misc{tensorflow_2024,
  title        = {TensorFlow},
  author       = {TensorFlow Team},
  year         = 2024,
  url          = {https://www.tensorflow.org/},
  note         = {Accessed: 2024-09-13}
}

@misc{tensorboard_2024,
  title        = {TensorBoard},
  author       = {TensorFlow Team},
  year         = 2024,
  url          = {https://www.tensorflow.org/tensorboard},
  note         = {Accessed: 2024-09-13}
}

@misc{netron_2024,
  title        = {Netron},
  author       = {Roeder, Lutz},
  year         = 2024,
  url          = {https://github.com/lutzroeder/netron},
  note         = {Accessed: 2024-09-13}
}

@misc{chatgpt_2024,
  title        = {ChatGPT},
  author       = {OpenAI},
  year         = 2024,
  url          = {https://openai.com/chatgpt/},
  note         = {Accessed: 2024-09-13}
}


@misc{seely_tensorflow_2024,
    author = {Welby Seely},
    title = {cosc592\_tensorflow},
    year = {2024},
    month = sep,
    howpublished = {\url{https://github.com/crimsonmagick/cosc592_tensorflow}},
    note = {Accessed: 2024-09-16}
}
